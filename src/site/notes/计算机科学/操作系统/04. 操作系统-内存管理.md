---
{"dg-publish":true,"permalink":"/计算机科学/操作系统/04. 操作系统-内存管理/","tags":["Operating-Systems","Memory"]}
---


# 概述

现代虚拟内存管理已经发展成了一个相当复杂的程序，包含诸如基址/界限等非常基本的技术，也涵盖了分段、分页、段页结合、多级页表、交换空间等高级概念。简单来讲，操作系统为每个进程提供一个假象——它拥有自己的庞大的私有内存空间，进程中的地址是虚拟的，操作系统和硬件负责将虚拟地址映射成真实地址，这样能够使得系统可以运行代码和数据量远大于真实内存的程序。



# 地址空间



## 时分共享

早期系统可能只运行某一特定程序，这样的局面不久后改变了，多道程序成为主流。为了能够在一台机子上运行多个程序，诞生了时分共享的方法，这就对内存管理提出了挑战：最省事的办法是让进程单独占用整块内存一小段时间，但是这样做切换的时间成本非常之高。另一种想法是在进程切换时，仍然将进程数据留在内存中，先不谈内存容量是否足够，首要要解决的是隔离问题——程序员必须保证一个进程不会在意料之外读写其他进程的内存（程序员的负担增加了）。

为了给程序员减负，最佳的做法是将内存管理交由操作系统自动完成。于是，地址空间这一抽象就产生了，每个进程可以在这个空间中“为所欲为”，隔离由操作系统负责。一个最简单的地址空间如下图所示，地址从低到高分别是代码段、堆、栈。

![一个简单的地址空间](https://s2.loli.net/2022/04/22/PoXtCUnAaWfmqkb.png)

> 像C语言中`printf("%p",&x)`打印的变量的地址实际上都是虚拟地址，而非内存中的物理地址。



## 地址映射

地址映射就是将虚拟地址转换成真实的物理地址。这个过程需要硬件和操作系统一起参与，具体来说，为了保证效率，地址转换由硬件计算，操作系统只在关键时刻介入（如配置硬件、管理空闲空间等）。

![完整映射到物理内存](https://s2.loli.net/2022/04/22/db3FxyB1al7HmkI.png)

我们假设进程的地址空间会完整地加载（映射）到物理内存中。如上图所示，一个大小为16KB的进程地址空间被完整加载到物理内存32KB~48KB的位置。这个映射过程由CPU上的内存管理单元（MMU）实现，该单元包含一个基址（base）寄存器和界限（bound）寄存器，在本例中，基址寄存器存储地址空间在物理内存中的起始地址（32KB），进程产生的所有内存引用，通过以下方式转换为物理地址：

```c
physical_address = virtual_address + base
```

界限寄存器负责越界保护，存储地址空间大小（16KB），如果进程需要访问超过这个界限或者为负数的虚拟地址，CPU将触发异常。

更详细地说，在地址重定位过程中，硬件需要提供以下支持，

+ 特权模式：以防用户模式的进程执行特权操作，只有操作系统能够执行硬件设置的特权指令；
+ 基址/界限寄存器：每个CPU需要一对寄存器来进行地址转换和界限检查；
+ 修改基址/界限寄存器的特权指令：在进程切换时，操作系统可以修改这对寄存器；
+ 地址转换和越界检查：完成地址转换和越界检查的电路；
+ 能够触发异常：如果用户程序试图使用特权指令和越界的内存；
+ 注册异常处理程序的特权指令：操作系统必须告诉硬件异常发生时要执行的代码；



操作系统必须在一些关键时刻介入，主要的职责如下：

+ 内存管理：进程创建时分配物理内存；进程终止时，回收内存；记录空闲内存；
+ 基址/界限管理：在上下文切换时设置基址/界限寄存器；
+ 异常处理：提供异常发生时的处理代码，比如终止错误进程；



# 分段



## 硬件支持

在前文我们假设将整块地址空间映射到物理内存中，这意味着堆和栈之间未使用的部分也占用了实际内存。

分段的想法是在MMU中引入不止一对基址/界限寄存器，而是给地址空间中的每个逻辑段一对寄存器（段寄存器），从而避免了未使用部分占用物理内存。

![在物理内存中放置段](https://s2.loli.net/2022/04/22/Br36XqHmdnCtA4v.png)

上图展示了代码段、栈、堆三个段在内存中的存放情况，它们的段寄存器可以是下表的样子。正向增长位影响地址映射时的计算方式，保护位决定了内存段共享时是否需要采用隔离措施。

| 段   | 基址 | 大小 | 是否正向增长 | 保护位 |
| ---- | ---- | ---- | ------------ | ------ |
| 代码 | 32KB | 2KB  | 1            | 只读   |
| 堆   | 34KB | 2KB  | 1            | 读写   |
| 栈   | 28KB | 2KB  | 0            | 读写   |



硬件在地址转换时需要知道地址引用了哪个段，通常有显式和隐式两种方法。显式就是用虚拟地址的开头几位标识不同的段，之后的位才是段内偏移量；在隐式方法中，硬件通过地址产生的方式来确定段，例如如果地址由程序计数器产生，那么地址在代码段，如果基于栈或基址指针，它一定在栈段。

在显式方式下，硬件的转换逻辑如下，

```c
segment = (virtual_address & SEG_MASK) >> SEG_SHIFT; // 获取段标识
offset = virtual_address & OFFSET_MASK; // 获取段内偏移
if (offset >= bounds[segment]) // 边界检查
    RaiseException(PROTECTION_FAULT);
else
    physical_address = base[segment] + offset; // 得到物理地址
    register = AccessMemory(physical_address);
```



## 操作系统支持

操作系统在上下文切换时必须对各个段寄存器中的内容进行保存和恢复。

![充满外部碎片的物理内存](https://s2.loli.net/2022/04/23/i4DvjOISfQ5Tor6.png)

第二个问题更重要，即空闲物理内存的管理。之前，我们假设地址空间是整块被映射的，并且每个进程的地址空间大小相同，所以物理内存可以划分为一些槽块。现在，每个进程都有一些段，段的大小也不同，导致物理内存到处都是空闲的小区域，即外部碎片，这些碎片很难有机会再被利用起来。

该问题的一种解决方案是重新安排原有的段，使它们互相紧凑，但这样的成本很高。更好的方法是依赖空闲列表管理算法，试图减少外部碎片。



## 空闲空间管理

无论是负责堆上内存分配的malloc库，还是操作系统在分段时的内存管理，都是采用了类似的空闲列表管理方法。两者的共同点都在于空闲空间由变长的单元构成，所以都会出现外部碎片。我们以malloc库为例，讨论空闲列表管理的底层机制和基本策略。



### 底层机制

我们将通过malloc分配的内存表示成下图所示的单元，其中size说明了具体内容的大小，magic提供完整性检查，白色部分才是存储实际内容的地方。所以如果请求N字节的内存，库不是寻找大小为N的内存块，而是寻找N加上头块大小的内存块。

![分配的内存单元](https://s2.loli.net/2022/04/22/LceqhHN7jEUKOnS.png)

空闲的内存我们表示成下图所示的单元，其中next是下一个空闲单元的地址，如此可以形成一条空闲单元链表。在最开始，堆没有分配任何内存，所以就只有这样一个空闲节点，我们从中可以得知这个堆的可用空间为4KB。

![image-20210506110120272](https://s2.loli.net/2022/04/22/1g5XvSwdKUjLlb9.png)

当我们连续通过malloc分配三次内存后，这个堆看起来如下图一样，

![空闲空间和3个已分配块](https://s2.loli.net/2022/04/22/a5C1feJKUTXGpAv.png)

有趣的是，当我们再以一定顺序通过free释放这三块已分配内存后，堆看起来就是一块具有四个节点的链表。虽然整个内存空间是空闲的，但却被分成了小段，形成了碎片化的空间，这时候内存管理系统明智的做法应当是遍历这个链表，合并相邻内存块。

![待合并的空闲空间](https://s2.loli.net/2022/04/22/uWwYqVE3H4gJS8P.png)



### 分配策略

理想的分配程序可以同时保证快速和碎片最小化。遗憾的是，由于分配和释放的请求序列是任意的，任何特定的策略在某组不匹配的输入下都会变得非常差，所以实际上并不存在“最好”的策略。

+ **最小匹配**：遍历整个空闲列表，返回不小于请求大小的最小空闲块。其想法很简单：选择最接近请求大小的块从而避免浪费；但是这有代价——需要遍历整个列表。
+ **最大匹配**：与最优匹配相反，总是尝试找最大的来切割。其想法是希望让空闲列表的块大小更加均匀，而不是像最优匹配那样可能剩下很多难以利用的小块。同样，该方法也需要遍历整个列表。
+ **首次匹配**：一旦找到不小于请求大小的块就返回。该方法具备速度优势，但是容易使得列表开头部分有很多小块（可以采用辅助的方法尽量让这些小块相邻以便合并）。
+ **下次匹配**：每次都从上次找到的位置继续往后找。其想法是将对空闲空间的查找操作扩散到整个列表中去，避免对开头的频繁分割，同时有具有很高的速度优势。
+ **分离空闲列表**：如果某个程序频繁地申请一种（或几种）大小的内存空间，那就拿出一部分内存专门满足这种大小的请求，并使用一个独立的列表进行管理。其它大小的请求则仍交给更通用的内存分配程序。**厚块分配程序**就属于该方法的一种。
+ **二分伙伴系统**：该方法考虑到合并对于分配程序的重要性，所以当有一个内存分配请求时，空闲空间就被递归地一份为二，直到刚好可以满足请求的大小。这种分配方式只能返回2的整数次幂大小的空闲块，因此存在内部碎片。伙伴系统的亮点在于块被释放时，可以很容易确定相邻内存，从而方便合并。
+ **其他策略**：更先进的分配程序采用更复杂的数据结构，以简单性换取性能，例子包括平衡二叉树、伸展树等等。



# 分页

## 基本原理



![分页映射后的物理内存](https://s2.loli.net/2022/04/22/7YPBFEzIhlOX2pS.png)

分页是将地址空间分割成固定长度的单元，每个单元称为一页。相应的，物理内存也被看作是定长槽块的阵列，叫作页帧。

虚拟地址空间的每一页都会被映射到物理上的一个页帧，这些映射关系存储在页表中。页表是属于进程的数据结构，即每个进程有自己独立的页表，页表也放在物理内存中。页表是由许多个固定长度的页表项（PTE）组成的，最常见的是按照虚拟页号顺序排成的线性结构，这样就很容易根据虚拟页号计算出对应页表项的地址。

页表项一般具有一下几个重要的内容：

+ PFN：物理页帧号；
+ 有效位：指示地址转换是否有效，比如没有使用的虚拟页对应的页表项就会被设置为无效；
+ 保护位：表明页是否可以读取、写入或执行；
+ 存在位：表明该页是在物理内存中还是在磁盘上；

x86系统中页表项的内容大概如下图所示。

![x86页表项](https://s2.loli.net/2022/04/22/lQStAuPb4B75oTj.png)



在分页的方式下，虚拟地址的高位是虚拟页面号（VPN），低位是页内偏移量，地址的换算可以用以下过程表示。

```c
VPN = (virtual_address & VPN_MASK) >> VPN_SHIFT; // 获取虚拟页号
PTEAddr = PTBR + VPN * sizeof(PTE); // 计算虚拟页号对应页表项的地址
PTE = AccessMemory(PTEAddr); // 读取页表项
if (PTE.valid == false)
    RaiseException(SEGMENTATION_FAULT); // 地址转换无效
else if (CanAccess(PTE.protection) == false)
    RaiseException(PROTECTION_FAULT); // 访问受限
else 
	offset = virtual_address & OFFSET_MASK; // 获取页内偏移
    physical_address = (PTE.PFN << PFN_SHIFT) | offset; // 得到物理地址
    register = AccessMemory(physical_address);
```



## 快速地址转换TLB

目前为止，地址的转换效率并不是很高，最主要的开销是每次转换都要从内存中读取一次页表项。改进的方案是使用地址转换旁路缓冲存储器，它能够缓存已经查询过的地址映射，并且支持并行查找，当再次查询到该映射时，就可以立即返回，避免了内存操作。该硬件算法如下过程所示。

```c
VPN = (virtual_address & VPN_MASK) >> VPN_SHIFT; // 获取虚拟页号
(success, TLBEntry) = TLB_Lookup(VPN);	// 查询TLB缓存
if (success == True)
    if (CanAccess(PTE.protection) == false)
    	RaiseException(PROTECTION_FAULT); // 访问受限
	else 
        offset = virtual_address & OFFSET_MASK; // 获取页内偏移
        physical_address = (TLBEntry.PFN << PFN_SHIFT) | offset; // 得到物理地址
        register = AccessMemory(physical_address);
else
    PTEAddr = PTBR + VPN * sizeof(PTE); // 计算虚拟页号对应页表项的地址
    PTE = AccessMemory(PTEAddr); // 读取页表项
    if (PTE.valid == false)
        RaiseException(SEGMENTATION_FAULT); // 地址转换无效
    else if (CanAccess(PTE.protection) == false)
        RaiseException(PROTECTION_FAULT); // 访问受限
    else 
        TLB_Insert(VPN, PTE.PFN, PTE.protection); // 新增缓存
		RetryInstruction(); // 重新查询，这次将命中TLB直接返回
```



映射缓存的设计基于的是两种假设：时间局部性和空间局部性。时间局部性是指，最近访问过的指令或数据可能很快会再次访问；空间局部性指的是，当程序访问内存地址x时，可能很快会访问邻近地址x+1的内存。以遍历数组为例，数组的元素大部分都会位于同一页中，那么只有第一个元素需要在内存中读取页表项，之后的元素都可以直接命中TLB，大大加速了地址转换。

TLB的内容和页表项有很多重叠的地方，毕竟设计它的目的就是减少对页表的访问。一条TLB项必然包含VPN和PFN，其次还有保护位、有效位和进程标识符等等。在上下文切换时，页表仍可以保留在内存中，只要更改页表指针寄存器PTBR的值即可。与此不同的是，TLB是进程间共用一份的，这就意味着在上下文切换时，它必须做好隔离工作——每个TLB项都有一个进程标识符（ASID），一个进程只能访问有自己标识的TLB项。例如下表中，属于标识为1进程的地址映射只有（10->100）和（11->50）；此外，我们还看到两个进程都映射到了物理内存的第50页，这就是进程间的共享内存了。

| VPN  | PFN  | ASID |
| ---- | ---- | ---- |
| 10   | 100  | 1    |
| 10   | 170  | 2    |
| 11   | 50   | 1    |
| 12   | 50   | 2    |

在一些特殊的应用场景下，一个程序短时间内访问的页数会超过TLB中的页数，就会产生大量TLB未命中，运行速度就会变慢。解决这个问题的一种方案是支持更大的页，即每页能容纳的数据量多了，使用的页自然就少了，像数据库系统中就普遍采用了这种方法。



## 优化页表存储

分页的第二个问题是页表占用的内存较大。一个32位的地址空间，4KB的页和4字节的页表项，将会生成4MB大小的页表，这还只是一个进程的情况，在实际系统中，通常有上百个活动进程，它们的页表可能同时驻留在内存中，占用数百兆的空间。因此，需要一些技术来减轻这种负担。



### 段页结合

段页结合的出发点是：由于地址空间大部分都没有使用，所以不需要为地址空间中的所有页都建立页表项。在分段基础上应用分页是个很巧妙的方法，具体来说，其做法如下：

+ 物理内存仍然被分割成一个个固定大小的页帧；
+ 地址空间中的每个逻辑段都有一个页表，记录属于该段的页映射；
+ 只有属于逻辑段的页才会被映射到物理内存；
+ 地址空间中的每个逻辑段都有一对基址/界限寄存器，基址寄存器指明段页表的起始地址，界限寄存器指明页表的大小；
+ 虚拟地址由三部分组成：段标识、VPN、偏移量；

![段页式内存映射](https://s2.loli.net/2022/04/23/xqlWyI5jQvhpCcZ.png)

可以看到，分段和分页优势互补，分段缩减了内存占用，分页则大大减少了外部碎片。但是，这种方式并没有完美地解决问题。首先，页表不再是固定大小，这意味着它的存储方式更为复杂，会导致外部碎片；其次，逻辑段中的未使用页仍然需要映射，例如有一个大而稀疏的堆，也会导致大量的页表浪费。



### 多级页表

页表的本质就是数据结构，我们可以对数据结构做很多疯狂的事情，让它们变大变小、变快变慢。前文页表都采用了线性结构，使得索引十分快速；我们也可以将它组织成树的形式，减少内存占用。以二级页表为例，引入了一个页目录，它由多个页目录项（PDE）构成。

如下图所示，线性页表可以看作是按VPN索引的PTE数组，占用了4个物理页帧，其中有许多无效的项，但是我们不能直接丢弃它们，否则会搅乱其他页表项的地址规律。二级页表则引入了一个页目录，它由多个页目录项（PDE）构成，每个有效的目录项都指向一个物理页帧，该物理页存放了部分的页表项。多级页表的关键在于，如果整页的页表项都无效，就不分配该页（例如PFN202和PFN203），只在页目录中用一个PDE项来占位，这样，地址的规律仍然没有被打破。

![线性（左）和二级（右）页表](https://s2.loli.net/2022/04/22/4q3AnKQuGUr7fJF.png)

线性页表必须连续存放在内存中，要找到这样一块连续空闲空间挑战不小。而多级页表的每个部分都可以整齐地放入一页中，并且不需要相邻存放。应该指出，多级页表也是有成本的：在TLB未命中时，需要额外的内存访问，即先读取页目录，再读取页表；另一方面，多级页表的结构也增加了系统的复杂性，但这些相对于宝贵的内存来说都不是问题。

![多级页表的虚拟地址](https://s2.loli.net/2022/04/22/TMhIAVyBwL4DtuQ.png)

如上图所示，多级页表中，虚拟地址的VPN高位用来表示PDE项的索引，低位表示页表项的索引。硬件进行地址转换的过程如下所示。

```c
VPN = (virtual_address & VPN_MASK) >> VPN_SHIFT; // 获取虚拟页号
(success, TLBEntry) = TLB_Lookup(VPN);	// 查询TLB缓存
if (success == True)
    if (CanAccess(PTE.protection) == false)
    	RaiseException(PROTECTION_FAULT); // 访问受限
	else 
        offset = virtual_address & OFFSET_MASK; // 获取页内偏移
        physical_address = (TLBEntry.PFN << PFN_SHIFT) | offset; // 得到物理地址
        register = AccessMemory(physical_address);
else
    PDEIndex = (VPN & PDE_MASK) >> PDE_SHIFT; // 页目录项索引
	PDEAddr = PDBR + PDEIndex * sizeof(PDE); // 页目录项地址
	PDE = AccessMemory(PDEAddr); // 获取页目录项内容
	if (PDE.valid = false) // 页目录项无效
        RaiseException(SEGMENTATION_FAULT); // 地址转换无效
	else 
        PTEIndex = (VPN & PTE_MASK) >> PTE_SHIFT; // 页表项索引
    	PTEAddr = (PDE.PFN << PFN_SHIFT) + PTEIndex * sizeof(PTE); // 页表项地址
        PTE = AccessMemory(PTEAddr); // 读取页表项
        if (PTE.valid == false)
            RaiseException(SEGMENTATION_FAULT); // 地址转换无效
        else if (CanAccess(PTE.protection) == false)
            RaiseException(PROTECTION_FAULT); // 访问受限
        else 
            TLB_Insert(VPN, PTE.PFN, PTE.protection); // 新增缓存
            RetryInstruction(); // 重新查询，这次将命中TLB直接返回
```



# 交换空间



## 机制

为了支持更大的地址空间（程序员可以不必担心数据是否有足够空间存储）和多道程序（物理内存无法一次容纳多个程序的所有页），操作系统一般只将进程的部分页放入到内存中，而其余部分放在硬盘的交换空间中。分页是交换空间机制能够运作的基础，因为操作系统是以页为单位进行换入换出的。页表项中的“存在位”用于记录页是在物理内存中还是在硬盘上。当存在位为0时，表明该页尚不在内存中，此时页表项的PFN位段被复用存放硬盘地址。

![物理内存和交换空间](https://s2.loli.net/2022/04/22/jXW6gqDArm3hVIp.png)

交换空间的运作过程如下：

+ 如果在查找地址映射时，TLB未命中，则硬件在内存中查找页表，并使用VPN找到该页的页表项；
+ 如果页有效但是存在于硬盘中，就会触发“页错误”，唤醒操作系统的页错误处理程序；
+ 处理程序首先为将要换入的页找到一个空闲的物理帧，如果没有找到，则等到交换算法运行从内存中换出一些页；
+ 获得物理帧后，处理程序发出IO请求从交换空间读取页；
+ 当硬件IO完成，操作系统会更新页表（标记该页存在，并更新PFN位段）和TLB缓存，并重试指令，下一次重新访问TLB将命中，找到地址映射；

其中，硬件负责的算法如下，

```c
VPN = (virtual_address & VPN_MASK) >> VPN_SHIFT; // 获取虚拟页号
(success, TLBEntry) = TLB_Lookup(VPN);	// 查询TLB缓存
if (success == True)
    if (CanAccess(PTE.protection) == false)
    	RaiseException(PROTECTION_FAULT); // 访问受限
	else 
        offset = virtual_address & OFFSET_MASK; // 获取页内偏移
        physical_address = (TLBEntry.PFN << PFN_SHIFT) | offset; // 得到物理地址
        register = AccessMemory(physical_address);
else
    PTEAddr = PTBR + VPN * sizeof(PTE); // 计算虚拟页号对应页表项的地址
    PTE = AccessMemory(PTEAddr); // 读取页表项
    if (PTE.valid == false)
        RaiseException(SEGMENTATION_FAULT); // 地址转换无效
    else if (CanAccess(PTE.protection) == false)
        RaiseException(PROTECTION_FAULT); // 访问受限
    else if (PTE.present == false)
        RaiseException(PAGE_FAULT); // 唤醒操作系统页错误处理程序
	else
        TLB_Insert(VPN, PTE.PFN, PTE.protection); // 新增缓存
		RetryInstruction(); // 重新查询，这次将命中TLB直接返回
```

操作系统的页错误处理程序如下，

```c
PFN = FindFreePhysicalPage(); // 查找空间物理帧
if (PFN = -1)
    PFN = WaitForSwap(); // 等待交换算法换出
DiskRead(PTE.DiskAddr, PFN); // 等待IO
PTE.present = true;
PTE.PFN = PFN;
TLB_Insert(VPN, PTE.PFN, PTE.protection); // 新增缓存
RetryInstruction(); // 重新查询
```

在上述过程中，进程将处于阻塞状态。操作系统可以运行其他可执行的进程，尤其是IO操作期间，更需要并发运行。

操作系统中会有一个后台线程专门负责页的交换，称为交换守护进程。该进程不会等待内存完全满了之后才运行，系统中通常会设置高低的水位线，来帮助决定何时从内存中清除页。并且，许多系统会设有缓冲区，等待多个要清除的页聚集，同时写入到交换区间，从而提高硬盘的效率。



## 策略

当内存占用较多时，决定将哪些页换出是一件很值得考虑的问题，它会极大地影响系统性能。页面置换算法和缓存淘汰策略类似，主要的目标是让缓存未命中最少，这样从磁盘中读取页的次数页最少。



### OPT

最优替换策略，该策略替换内存中在最远将来才会被访问到的页，可以达到缓存未命中率最低。由于需要该策略需要知道未来的事情，所以只是理论上的算法，主要用于和其他策略进行对比，衡量其他策略的优劣程度。

```c
0, 1, 2, 0, 1, 3, 0, 3, 1, 2, 1
```

例如一个程序按如上顺序访问虚拟页，内存最多容纳3页，则当程序要访问页3时，将换出页2，因为距离页2再次被访问的时间最长。



### FIFO

FIFO按照队列方式换出页，是易于实现的替换策略，但是未命中率较高。并且会导致“Belady异常”——当内存容量从3页变大为4页时，命中率反而下降。

```c
1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 // 内存访问的虚拟页
0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1 // 内存大小为3时的命中情况，0代表未命中
0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0 // 内存大小为3时的命中情况，0代表未命中
```



### LRU
{ #a3c509}


利用局部性原则，如果一个页被频繁地访问或者最近刚被访问，那么再次访问的可能性就更大，所以可以根据历史数据统计页的重要性，可以利用的信息包括频率和近期性，如“最不经常使用”策略（LFU，Least-Frequently-Used）会替换最不经常使用的页；“最少最近使用”策略（LRU, Least-Recently-Used）替换最近最少使用的页。

以LRU为例，需要在内存中维护一个所有页面的链表，每当一个页面被访问时，就将这个页面移动到链表头部，换出时选择链尾的页。这种方法最坏的情况是遍历所有的页面，在实际系统中，内存中可能存在几十万数量的页，全部遍历一遍的代价过于昂贵。所以，更具可应用性的是一些近似LRU方法，即只找较旧的页，而不是最旧的。



### 时钟算法

时钟算法是近似LRU的一个例子，通过在页表项中增加一个使用位表示该页是否最近被使用过。然后系统中将所有页组织成一个环形链表，时钟指针每次递增，如果页的使用位为1就将其置0，否则终止搜索过程，将指针所指的页换出。

![时钟算法](https://s2.loli.net/2022/04/22/BO3sMayZoh8x64c.png)



### 二次机会列表

FIFO算法可能会把经常使用的置换出去，为了避免这个问题，提出了二次机会列表。

即设置两个FIFO队列，第一个队列同FIFO算法，当有新页放入队尾时，队首的页被拿出，但并不立即丢弃，而是放入到第二个FIFO的队尾；当系统决定要换出一些页时，踢出第二个FIFO队首的页面；如果第二个FIFO中的页面在被回收之前再次被访问，则被取出放回到第一个FIFO的队尾。



# 总结

为了让程序员开发时不必关心代码和数据在实际内存中的存放问题，内存管理系统提出了地址空间这一抽象。在映射到物理内存时，考虑到地址空间未使用的部分没有必要装载到内存，所以对地址空间进行了分段，但这导致了外部碎片，为操作系统的空闲空间管理增加了难度，尽管有许多空间的分配策略，但是这些策略最终只是尽量减少碎片量而已。

导致外部碎片的根源在于空间单位的大小可变，因此分页从这一点出发将空间分割成了固定大小，从而避免了外部碎片（虽然又会出现内部碎片）；此外，分页也可以支持更大的地址空间，通过和磁盘上的交换空间进行页的换入和换出，使得多道程序可以运行在有限容量内存的系统上。但是分页需要使用页表来管理映射，一方面使得页查找的速度下降，另一方面页表本身也会占用较多内存。前者可以通过缓存映射来优化；针对后者，则讨论了段页式、多级页表这两种方案，它们核心的想法是一致的：很多无效映射没有必要分配页来存储。段页式吸收了分段的优点，但是解决问题并不彻底；多级页表使用了复杂的数据结构，并且使得页表的存储更加灵活，不足之处在于会降低页访问速度。

最后，讨论了交换空间的应用，分析了多种页面置换策略，这些策略的优劣会在很大程度上影响系统的性能。