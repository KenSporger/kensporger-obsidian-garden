---
{"dg-publish":true,"permalink":"/计算机科学/操作系统/05. 操作系统-锁/","tags":["Operating-Systems","Concurrent","Lock","Data-Structure","High-Performance"]}
---


在并发编程中，锁被用来确保一段程序的**原子性**——通过在临界区附近加锁，保证临界区内的代码能够像单条原子指令一样执行。它本质上还是一个变量，只不过是存储了一些特殊的信息，如锁的状态（是否被某个线程持有）、持有该锁的线程ID、请求获取锁的线程队列等。

锁有多种类型，本文主要讨论**互斥锁**。基于UNIX系统的POSIX库提供了Pthread锁（C++标准库中还提供`std::mutex`，它是对Pthread锁的封装），其用法大致如下，

```c++
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_lock(&lock);
var++;
pthread_mutex_unlock(&lock);
```



锁的实现必须借助硬件和操作系统：硬件实现了一些具备原子性的指令（硬件原语）；操作系统则在提高并发性能上给予了帮助。我们总是希望能够实现一些近乎完美的东西，对于锁来说，成功的设计要符合以下三个目标：

+ **互斥性**：锁要有效地阻止多个线程进入临界区；
+ **公平性**：每个竞争线程不至于出现一直获取不到锁而饿死的情况（放任不管，随机竞争是不公平的）；

+ **高性能**：关注使用锁之后增加的系统开销，通常要考察单线程、单CPU上多线程竞争、多CPU上多线程竞争情况下的性能。





# 硬件原语



## 控制中断

最早的互斥方案是在进入临界区时关闭系统全局中断，离开时重新使能。这与单片机中防止中断嵌套的操作很相像，事实上，这个方案当初就是为单处理器系统开发的。

该方案保证了临界区代码不会被中断，从而原子性地执行，但是也存在许多严重的缺陷：

+ 不安全：向应用程序开放了开关系统中断的特权操作；
+ 不支持多处理器：关闭中断仅对当前CPU有效，线程还可以正常运行在其他处理器上；
+ 关闭中断导致中断丢失：关闭中断期间，CPU会错过一些重要通知（如磁盘完整读请求）；



## 测试并设置

一个最简单的想法就是用变量来标志锁是否被占用，但变量的原子更新需要由硬件保证——**测试并设置指令**是最简单的硬件支持，也称为原子交换，该指令返回`old_ptr`指向的旧值，同时更新为`new`的新值，并且保证这个过程是原子的。

```C
int TestAndSet(int *old_ptr, int new){
	int old = *old_ptr;
	int *old_ptr = new;
	return old;
}
```

基于该指令，我们很容易实现一个**自旋锁**：一旦一个线程率先执行了`TestAndSet`，其他线程读取到`lock->flag`为1就会原地等待。

```c
typedef struct lock_t
{
    int flag;
} lock_t;

void init(lock_t* lock)
{
    // 0：未被占用
    // 1：被占用
    lock->flag = 0;
}

void lock(lock_t *lock)
{
    // 自旋等待
    while (TestAndSet(&lock->flag, 1) == 1);
}

void unlock(lock_t *lock)
{
    // 释放锁
    lock->flag = 0;
}
```

回到最初的设计初衷，对自旋锁的评价如下：

+ 满足互斥性：自旋锁一次只允许一个线程进入临界区；
+ 不满足公平性：自旋的线程可能会永远自旋，导致饿死；
+ 性能总体较差：单CPU情况下，如果有N个线程，那么最坏的情况就是N-1个线程在原地各自旋一个时间片，浪费CPU周期；在多CPU情况下，假设每个CPU上有一个线程，那么一个线程自旋不影响其他CPU，性能还算可以；



## 获取并增加

类似于测试并设置指令，区别在于更新时会自增一。

```
int FetchAndAdd(int *ptr)
{
	int old = *ptr;
	*ptr = old + 1;
	return old;
}
```



## 比较并交换

```C
int CompareAndSwap(int *ptr, int expected, int new)
{
    int actual = *ptr;
    if (actual == expected)
        *ptr = new;
    return actual;
}

// 利用CompareAndSwap实现自旋锁
void lock(lock_t *lock)
{
    while (CompareAndSwap(&lock->flag, 0, 1) == 1);
}
```

**比较并交换**只在`ptr`等于`expected`时才更新为`new`值，该指令比测试并设置指令更为强大，即可以实现自旋锁，也可以实现**无等待同步**（所谓的CAS机制）。



## 链接加载和条件式存储指令

```C
int LoadLinked(int *ptr)
{
    return *ptr;
}

int StoreConditional(int *ptr, int value)
{
    if (NoChangeAfterLoad())
    {
        *ptr = value;
        return 1;
    }
    else 
    {
        return 0;
    }
}

// 实现自旋锁
void lock(lock_t *lock)
{
    while (LoadLinked(&lock->flag) || !StoreConditional(&lock->flag, 1));
}
```

该套指令的关键在于每次`LoadLinked`后，仅第一次`StoreConditional`的调用会更新`ptr`指向的值。

+ 由于lock函数本身不具备原子性，所以我们不妨假设线程A、B都执行了`LoadLinked`；
+ 假设线程A在竞争中率先执行了`StoreConditional`，因为它是加载后第一调用者，所以更新`lock->flag`为1，持锁进入临界区；
+ 当线程B执行`StoreConditional`时，因为是第二调用者，所以函数返回0，使其进入自旋。



## Ticket锁

目前，我们实现的锁都无公平性可言，Mellor-Crummey和Michael-Scott提出了Ticket锁（这是一个非常有趣的锁）。

+ 线程调用lock函数会获取一张通向临界区的“门票”，门票的号码按照线程调用顺序分配；
+ 线程自旋等待时查询“当前可进入的票号”，如果没有轮到自己则继续等待；
+ 线程调用unlock时，会“递增当前可进入的票号”；

这里我们采用获取并增加指令来实现。

```c
typedef struct lock_t
{
    int ticket;
    int turn;
} lock_t;

void lock_init(lock_t *lock)
{
    lock->ticket = 0;
    lock->turn = 0;
}

void lock(lock_t *lock)
{
    int myturn = FetchAndAdd(&lock->ticket);
    while (lock->turn != myturn);
}

void unlock(lock_t *lock)
{
    FetchAndAdd(&lock->turn);
}
```



# 操作系统原语



## 转为就绪态

通过硬件的支持，我们已经实现了互斥、公平的自旋锁。然而自旋锁的性能着实令人堪忧，亟需改进。

一个简单的完善想法就是在要自旋的时候，放弃CPU时间片。比如利用操作系统提供的原语`yield()`，线程调用后将从运行态转变为就绪态。

```C
// 重写测试并设置指令实现的lock函数
void lock(lock_t *lock)
{
    while (TestAndSet(&lock->flag, 1) == 1) 
        yield();// 让出CPU
}
```

这种方法相对自旋有了很好的性能提升，然而上下文切换的成本依然很高——假设有N个线程并采用某种轮转调度程序，那么就有N-1个线程会一直处于运行-让出这种模式，直到持有锁的线程再次运行。

其次，公平性也无法得到保证，一个线程可能始终处于让出的循环，而某些线程则反复进出临界区。



## 转为阻塞态

更明智的做法是将自旋线程从运行态转变为阻塞态，直到其他线程重新唤醒它。操作系统提供了原语`park()`和`unpark(threadID)`，前者让当前线程休眠，后者唤醒特定线程。对于公平性问题，使用队列来施加控制，排除调度上的偶然性。

```C
typedef struct queue_lock_t
{
    int flag;
    spin_wait_lock_t guard;
    queue_t *q;
}queue_lock_t;

void queue_lock_init(queue_lock_t *lock)
{
    lock->flag = 0;
    spin_wait_lock_init(&lock->guard);
    queue_init(lock->q);
}

void queue_lock(queue_lock_t *lock)
{
    spin_wait_lock(&lock->guard); // 自旋锁
    if (lock->flag == 0) 
    {
        lock->flag = 1; // 标志持锁
        spin_wait_unlock(&lock->guard);
    }
    else
    {
        queue_add(lock->q, gettid());
        spin_wait_unlock(&lock->guard);
        park(); 
    }
}

void queue_unlock(queue_lock_t *lock)
{
    spin_wait_lock(&lock->guard);
    if (queue_empty(lock->q))
        lock->flag = 0;
    else
        unpack(queue_remove(lock->q));
    spin_wait_unlock(&lock->guard);
}
```

`guard`是一个自旋锁，其实现可以采用上文中的任何硬件原语。它一方面确保`queue_lock`和`queue_unlock`中临界区的线程隔离；另一方面允许线程自旋一段时间等待锁的获取，减少线程状态的切换。我们不妨作以下情况讨论：

+ 线程A率先执行`queue_lock`，并更新`lock->flag`为1，之后又立刻调用了`queue_unlock`释放`guard`锁，由于此时队列中没有等待线程，所以重置`lock->flag`为0。

+ 接着，线程B、C调用`queue_lock`，线程B抢到锁，线程C开始自旋；
+ 线程B更新`lock->flag`为1，在`queue_lock`返回之后，线程C取得锁，但由于`lock->flag=1`，线程C加入队列并休眠；
+ 线程B调用`queue_unlock`，唤醒线程C；线程C从`park()`之后的代码开始执行，此时`lock->flag`仍然是1；

上述过程表明了我们实现的是一个两阶段锁，综合了自旋和休眠的优势。

> **两阶段锁**：自旋在有些情况（很快要释放锁）下可能很有用，因此两阶段锁的第一阶段先会自旋一段时间（通常是自旋固定的次数），希望它可以获取锁；如果第一阶段没有获取锁，则第二阶段调用者就会睡眠直到锁可用。



最后，你可能已经注意到了上述代码中的竞争条件：假设系统中存在线程A、B，线程A正处于临界区，线程B被加入了队列，且即将调用`park()`，此时因为线程B已经释放了`guard`锁，线程A得以调用`queue_unlock`提前对线程B进行唤醒（唤醒无效），之后线程B调用`park()`将永远睡去（没有在队列中但休眠了）。避免这种处境的方法之一是借助系统调用`setpark()`，它告诉线程B马上要park，如果此时另一个线程A被调度并且调用了`unpark()`，那么后续线程B调用`park()`时将直接返回而不进入休眠。

```c
// 利用setpark修改代码
queue_add(lock->q, gettid());
setpark();
spin_wait_unlock(&lock->guard);
park(); 
```



# 基于锁的并发数据结构

本节介绍如何利用C++标准库的`mutex`来对常用的数据结构进行加锁以支持高性能的并发访问。



## 并发计数器

简单实现：

```C++
class Counter
{
public:
    Counter(int v):value(v){}
    void increase()
    {
        lock.lock();
        value++;
        lock.unlock();
    }
    int get(){
        lock.lock();
        int temp = value;
        lock.unlock();
        return temp;
    }
private:
    int value;
    mutex lock;
};
```


懒惰计数器版本：通过多个局部计数器和一个全局计数器实现一个逻辑计数器，其中每个线程有一个局部计数器，每个局部计数器有一把自己的锁。线程递增自己的局部计数器，为了保持全局更新，当局部计数器达到阈值T时加到全局计数器上；T的大小影响全局计数器的精度和性能。总之，懒惰计数器在准确性和性能之间做了折中。

```C++
template<int N>
class LazyCounter
{
public:
    LazyCounter(int v, int t):global_value(v), threshold(t){}
    void increase(int threadID)
    {
        local_lock[threadID].lock();
        local_value[threadID]++;
        if (local_value[threadID] >= threshold)
        {
            global_lock.lock();
            global_value += local_value[threadID];
            global_lock.unlock();
            local_value[threadID] = 0;
        }
        local_lock[threadID].unlock();
    }
    int get(){
        global_lock.lock();
        int temp = global_value;
        global_lock.unlock();
        return temp;
    }
private:
    int local_value[N];
    mutex local_lock[N];
    int global_value;
    mutex global_lock;
    int threshold;
};
```



## 并发链表

```C++
struct node_t
{
    node_t(int v, node_t* n):value(v), nxt(n){}
    int value;
    node_t* nxt;
};

class MyList
{
public:
    MyList():head(NULL){}
    void insert(int key)
    {
        node_t* new_node = new node_t(key, NULL);
        lock.lock();
        new_node->nxt = head;
        head = new_node;
        lock.unlock();
    }

    node_t* find(int key)
    {
        lock.lock();
        node_t* cur = head;
        while (cur != NULL && cur->value != key) cur = cur->nxt;
        lock.unlock();
        return cur;
    }

private:
    node_t* head;
    mutex lock;
};
```

需要注意的是加锁位置，例如`insert`函数中没有必要对`new_node`创建加锁，这是因为该语句不涉及临界区——如果我们将这句代码改为下面这样，就必须要加锁，因为它用到了head变量。

```c++
node_t* new_node = new node_t(key, head);
```

其次，你可能想到为每个节点分配一个锁，以增加程序的并发，这样的链表结构叫**过手锁链**。过手锁链增加了链表的并发程度，但是实际在遍历时，每个节点获取锁、释放锁的开销巨大，很难比采用一把大锁来得快。也许某种杂合的方案更好，这一点可以参考MySQL的锁机制设计。

> **高并发并不意味着高性能**，如果方案带来了大量的开销（例如频繁地获取和释放锁），那么高并发就没有什么意义。



## 并发队列

因为队列只对头尾节点进行操作，所以只要为头尾节点分配两把锁即可。

```C++
struct node_t
{
    node_t(int v, node_t* n):value(v), nxt(n){}
    int value;
    node_t* nxt;
};

class MyQueue
{
public:
    MyQueue(){
        head = tail = new node_t(0, NULL); // head是虚拟节点，tail指向最后一个真实节点
    }
    void push(int key)
    {
        node_t* new_node = new node_t(key, NULL);
        tailLock.lock();
        tail->nxt = new_node;
        tail = new_node;
        tailLock.unlock();
    }

    int pop()
    {
        headLock.lock();
        node_t* new_head = head->nxt;
        if (new_head == NULL)
        {
            headLock.unlock();
            return -1;
        }
        int key = new_head->value;
        delete head;
        head = new_head;
        headLock.unlock();
        return key;
    }

private:
    node_t* head;
    node_t* tail;
    mutex headLock;
    mutex tailLock;
};
```



## 并发散列表

散列表可以用数组实现，每个数组元素都是一个散列桶（链表），我们只要对每个散列桶加锁，于是可以复用前面定义的并发链表。

```C++
template<int N>
class MyHash
{
public:
    void insert(int key)
    {
        int bucket = key % N;
        lists[bucket].insert(key);
    }
    bool find(int key)
    {
        int bucket = key % N;
        return lists[bucket].find(key) != NULL;
    }
private:    
    MyList lists[N];
};
```



